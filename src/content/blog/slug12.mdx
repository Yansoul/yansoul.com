---
title: '山雨欲来了'
description: ''
date: '2025-10-12'
---


今天发现一个刚发布的很惊艳的模型：https://gaga.art/
效果演示：
- https://static.sandcdn.com/uploads/146b371a-c828-4797-a6d0-003af3969132.mp4
- https://static.sandcdn.com/uploads/296d0109-c06d-45ea-8ea2-e91acfa7ba50.mp4
- https://static.sandcdn.com/uploads/25a2b86b-b93e-4ab1-87d4-9276f2577617.mp4


过去的数字人确实能做到让一个人说话，但观众明显还是会有「这不是真人」的心知肚明。
如今这个效果，可以预见的未来是，数字人产品大概率还要迎来一波大增长。

背后变化的原因还是在于技术范式的转变——
- heygen 那一类早期数字人，多是文字转语音（tts）+音频自动对口型的工程化思路，但「表达」这件事不只是单纯把口型对上，真人在说话时，眼神、面部肌肉、肢体动作的变化都是与表达的语言有机地结合在一起的。tts+对口型只能解决嘴唇层面的问题，整体层面的神态是无法解决的
- veo3，sora2，gaga 这类近俩月的模型，都是音视频多模特的范式，音频+图像的视频端到端生成，简直是又一次降维打击。

在技术层面，先是文字做到了难以区分人/机，然后是图片层面难以区分真人 or AI，似乎视频层面的这一步，也快到来了。
数字人及其相关的场景，也许会面临一些洗牌。
也许。


---